---
layout: page
permalink: /blogs/206yingjian/index.html
title: J.P.M Quantitative Project
---

## J.P.M Quantitative 

---

### ğŸ”¥Task1 

>é€‰å–äº”åªè‚¡ç¥¨è¿›è¡Œæœ‰æ•ˆå‰æ²¿çš„ç»˜åˆ¶ä»¥åŠç»™å®šé¢„æœŸæ”¶ç›Šçš„æœ€ä½³æŒä»“é…æ¯”æ±‚è§£


### ğŸ´ å…·ä½“ä»»åŠ¡å®ç°çš„ç®—æ³•

1.æœ‰æ•ˆå‰æ²¿çš„ç»˜åˆ¶ï¼š*sco*

2.æœ€ä½³æŒä»“é…æ¯”æ±‚è§£ï¼š*cvxopt/sco*

<br>The efficient frontier represents the best combinations of risk and expected return, which offer the highest expected return at a given level of risk or the lowest risk for a given expected return.æœ‰æ•ˆå‰æ²¿ä½œä¸ºä»£è¡¨äº†ä¸€ç»„é£é™©å’Œé¢„æœŸå›æŠ¥ä¹‹é—´çš„æœ€ä½³ç»„åˆï¼Œè¿™äº›ç»„åˆåœ¨ç»™å®šçš„é£é™©æ°´å¹³ä¸‹æä¾›äº†æœ€é«˜çš„é¢„æœŸå›æŠ¥ï¼Œæˆ–è€…åœ¨ç»™å®šçš„é¢„æœŸå›æŠ¥ä¸‹å…·æœ‰æœ€ä½çš„é£é™©ã€‚

<center>
<img src = "/blogs/206yingjian.assets/æœ‰æ•ˆå‰æ²¿2.png">
</center>

   
---
### åŸºç¡€æ•°æ®åŠå…¶ç‰¹å¾å±•ç¤º

````python    
```
    pip install cvxopt
    pip install yfinance #ä¸‹è½½è‚¡ç¥¨æ•°æ®
````


````python
```
    import numpy as np
    import pandas as pd  
    import matplotlib.pyplot as plt  
    from cvxopt import matrix, solvers
    import yfinance as yf 

    # è·å–è‚¡ç¥¨æ•°æ®  
    tickers = ['GOOG', 'MSFT', 'AAPL', 'NVDA', 'AMZN']  
    data = yf.download(tickers, start='2024-01-01', end='2024-10-01')['Adj Close']

    data.shift(1) #åˆ›é€ ä¸€è¡Œç©ºè¡Œç”¨äºè®¡ç®—æ”¶ç›Šç‡

    #å°†è‚¡ç¥¨æŒ‰ç…§åˆå§‹äº¤æ˜“æ—¥è¿›è¡Œå½’ä¸€åŒ–å¤„ç†å¹¶å¯è§†åŒ–
    (data/data.iloc[0]).plot(figsize=(10,6),grid=True)

````
<center>
<img src = "/blogs/206yingjian.assets/Return Rate.png">
</center>

---
### ç®—æ³•å®ç°

#### æŠ•èµ„ç»„åˆå¯è¡Œè§£
````python
```
    #éšæœºè¿›è¡Œ2000æ¬¡æ¨¡æ‹Ÿ  
    #Rp_list,Vp_liståˆ†åˆ«å­˜å‚¨æ¯ä¸ªæ¨¡æ‹ŸæŠ•èµ„çš„é¢„æœŸæ”¶ç›Šç‡å’Œæ³¢åŠ¨ç‡
    n=5   #äº”åªè‚¡ç¥¨äº”ä¸ªæŠ•èµ„ç»„åˆ
    I=2000
    Rp_list=np.ones(I)  #é¢„æœŸæ”¶ç›Šç‡
    Vp_list=np.ones(I)  #æ³¢åŠ¨ç‡
    SR_list=np.ones(I)  #å¤æ™®æ¯”ç‡

    #æ¨¡æ‹Ÿè¿‡ç¨‹
    for i in np.arange(I):
       x=np.random.rand(n)  #ç”Ÿæˆnä¸ªéšæœºæƒé‡
       weights=x/sum(x)     #æƒé‡å½’ä¸€åŒ–ï¼Œä½¿å…¶å’Œä¸º1
       Rp_list[i]=np.sum(weights*Manual_LR)  
       Vp_list[i]=np.sqrt(np.dot(weights,np.dot
(Cov_LR,weights.T)))  
       SR_list[i]=Rp_list[i]/Vp_list[i]

    #å±•ç¤ºç»“æœ    
    plt.figure(figsize=(8, 4), dpi=100, facecolor='white')  
    plt.scatter(Vp_list, Rp_list)  
    plt.title('The relationship between expected portfolio return and volatility', pad=20)  
    plt.xlabel('Volatility', labelpad=20)  
    plt.ylabel('Expected Return', labelpad=20)  
    plt.grid()

````

<center>
<img src = "/blogs/206yingjian.assets/The relationship between expected portfolio return and volatility.png">
</center>

---
#### æŠ•èµ„ç»„åˆçš„æœ‰æ•ˆå‰æ²¿
````python
```
    import scipy.optimize as sco

   #å¿…è¦å‚æ•°æ„å»º
    def f(w):
       w=np.array(w)
       Rp_opt=np.sum(w*Manual_LR)
       Vp_opt=np.sqrt(np.dot(w,np.dot(Cov_LR,w.T)))
       return np.array([Rp_opt,Vp_opt])

    def Vmin_f(w):
       return f(w)[1]

    cons=({'type':'eq','fun':lambda x:np.sum(x)-1},{'type':'eq','fun':lambda x:f(x)[0]-0.15})
    bnds=((0,1),(0,1),(0,1),(0,1),(0,1))

    #æƒé‡å†³å®šé‡è¦æ€§
    w0=np.array([0.2, 0.2, 0.2, 0.2, 0.2])  
    result=sco.minimize(fun=Vmin_f,x0=w0,method='SLSQP',bounds=bnds,
    constraints=cons)
    cons_vmin=({'type':'eq','fun':lambda x:np.sum(x)-1})
    result_vmin=sco.minimize(fun=Vmin_f,x0=w0,
    method='SLSQP',bounds=bnds,constraints=cons_vmin)

    Vp_vmin=result_vmin['fun']
    Rp_vmin=np.sum(Manual_LR*result_vmin['x'])
 
    Rp_target=np.linspace(Rp_vmin,0.95,300)
    Vp_target=[]

    for r in Rp_target:
      cons_new=({'type':'eq','fun':lambda x:np.sum(x)-1},{'type':'eq','fun':lambda x:f(x)[0]-r})
      result_new=sco.minimize(fun=Vmin_f,x0=w0,
      method='SLSQP',bounds=bnds,constraints=cons_new)
       Vp_target.append(result_new['fun'])

    #å±•ç¤ºç»“æœ    
     plt.figure(figsize=(8, 4))  
     plt.scatter(Vp_list,Rp_list,c=SR_list, cmap='YlGnBu', marker='o')  
     plt.colorbar(label='Sharpe Ratio')  
     plt.plot(Vp_target,Rp_target,'r-',label="efficient frontier")
     plt.scatter(sdp, rp, marker='*', color='r', s=300, label='Max Sharpe Ratio')  
     plt.title('Efficient Frontier')  
     plt.xlabel('Annualized Volatility')  
     plt.ylabel('Annualized Return')  
     plt.legend(labelspacing=0.8)  
     plt.show()
````
<center>
<img src = "/blogs/206yingjian.assets/Efficient Frontier.png">
</center>

---
#### å¿…è¦å‚æ•°è®¾ç½®
> è‚¡ä»·æ”¶ç›Šç‡ä¸èƒ½å¤„ç†å¯¹ç§°å¤„ç†ä¸Šæ¶¨å’Œä¸‹è·Œï¼Œå¢åŠ 50%å’Œå‡å°‘50%çš„å½±å“ä¸ä¼šç›¸äº’æŠµæ¶ˆ,å¤šæœŸæ”¶ç›Šè®¡ç®—å®¹æ˜“äº§ç”Ÿç´¯ç§¯è¯¯å·®ï¼Œé€‚åˆåˆ†æä¸è¿ç»­æ€§çš„æ”¶ç›Šäº‹ä»¶ï¼Œå¦‚åˆ†çº¢å’Œå…¶ä»–ä¸€æ¬¡æ€§æ”¶ç›Šã€‚<br>å¯¹æ•°æ”¶ç›Šç‡ï¼šå‡è®¾å¸‚åœºæ˜¯è¿ç»­å¤åˆ©çš„ï¼Œå¯¹æ•°æ”¶ç›Šç‡æ›´åæ˜ çœŸå®æ”¶ç›Šï¼Œä¸Šä¸‹æ³¢åŠ¨å¯¹ç§°ï¼Œä¸”å¤šæœŸæ”¶ç›Šå¯ä»¥ç®€å•ç›¸åŠ è€Œä¸äº§ç”Ÿç´¯ç§¯è¯¯å·®ï¼Œæ›´é€‚åˆæ­£æ€åˆ†å¸ƒå‡è®¾,é•¿æœŸæŠ•èµ„å’Œå¤æ‚çš„é‡‘èæ¨¡å‹é€‚åˆä½¿ç”¨å¯¹æ•°æ”¶ç›Šç‡ã€‚

````python
```
    #è®¡ç®—è‚¡ç¥¨çš„å¯¹æ•°æ”¶ç›Šç‡å¹¶ä¸”å±•ç¤ºæè¿°æ€§ç»Ÿè®¡æŒ‡æ ‡
    Log_return=np.log(data/data.shift(1))
    #è®¡ç®—è‚¡ç¥¨çš„å¹´å¹³å‡æ”¶ç›Šç‡  é€šè¿‡è®¡ç®—è¯¥åºåˆ—çš„ç®—æœ¯å¹³å‡å€¼çš„åˆ°å¹³å‡å¯¹æ•°æ”¶ç›Šç‡
    Manual_LR=Log_return.mean()*252
    #è®¡ç®—è‚¡ç¥¨æ”¶ç›Šç‡çš„å¹´åŒ–æ³¢åŠ¨ç‡  è®¡ç®—å¹³å‡æ³¢åŠ¨ç‡åå¹´åŒ–
    Vol_LR=Log_return.std()*np.sqrt(252)
    #è®¡ç®—è‚¡ç¥¨çš„åæ–¹å·®çŸ©é˜µå¹¶è¿›è¡Œå¹´åŒ–å¤„ç†
    Cov_LR=Log_return.cov()*252
    #è®¡ç®—è‚¡ç¥¨çš„ç›¸å…³ç³»æ•°çŸ©é˜µ
    Corr_LR=Log_return.corr()

````
---
#### èµ„æœ¬å¸‚åœºçº¿
````python
``` 
    Rf=0.03  #æ— é£é™©åˆ©ç‡
    def F(w):
       w=np.array(w)
       Rp_opt=np.sum(w*Manual_LR)
       Vp_opt=np.sqrt(np.dot(w,np.dot(Cov_LR,w.T)))
       Slope=(Rp_opt-Rf)/Vp_opt
       return np.array([Rp_opt,Vp_opt,Slope])

    def Slope_F(w):
          return -F(w)[-1]

    w1=np.array([0.2, 0.2, 0.2, 0.2, 0.2])
    cons_Slope=({'type':'eq','fun':lambda x:np.sum(x)-1})
    result_slope=sco.minimize(fun=Slope_F,x0=w1,method='SLSQP',bounds=bnds,
constraints=cons_Slope)

    Rm=np.sum(Manual_LR*wm)
    Vm=(Rm-Rf)/Slope
    Rp_CML=np.linspace(Rf,0.95,200)
    Vp_CML=(Rp_CML-Rf)/Slope

    #å±•ç¤ºç»“æœ    
    plt.figure(figsize=(8, 4))  
    plt.scatter(Vp_list,Rp_list,c=SR_list, cmap='YlGnBu', marker='o')  
    plt.colorbar(label='Sharpe Ratio')  
    plt.plot(Vp_target,Rp_target,'r-',label="efficient frontier")
    plt.plot(Vp_vmin,Rp_vmin,'g*',label='Global minimum volatility',markersize=13)
    plt.plot(Vp_CML,Rp_CML,'b--',label='market portfolio',markersize=13)
    plt.scatter(sdp, rp, marker='*', color='r', s=300, label='Max Sharpe Ratio')  
    plt.title('Efficient Frontier')  
    plt.xlabel('Annualized Volatility')  
    plt.ylabel('Annualized Return')  
    plt.legend(labelspacing=0.8)  
    plt.show()
````
<center>
<img src = "/blogs/206yingjian.assets/Total_Efficient Frontier.png">
</center>

---
#### åŸºäºcvxoptçš„èµ„äº§ç»„åˆé…ç½®

````python
```
   #è®¡ç®—æ¯ä¸ªè‚¡ç¥¨æ—¥æ”¶ç›Šç‡çš„ç™¾åˆ†æ¯”å˜åŒ–å¹¶ä¸”ç§»é™¤æ‰æœ‰ç¼ºå¤±å€¼çš„è¡Œ  
   returns = data.pct_change().dropna()  
 
   cov_matrix = returns.cov() * 252  # å¹´åŒ–åæ–¹å·®çŸ©é˜µ  
   print(cov_matrix)  

   #é€‰ç”¨cvxoptï¼Œä½œä¸ºå‡¸ä¼˜åŒ–é—®é¢˜çš„å·¥å…·çš„é»˜è®¤å‚æ•°å·²ç»æ¯”è¾ƒé«˜æ•ˆï¼Œå¦‚æœæƒ³è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ï¼Œå¯ä»¥
   #é€šè¿‡ä¼˜åŒ–çŸ©é˜µè¡¨ç¤ºï¼ˆå¦‚åˆ©ç”¨ç³»æ•°çŸ©é˜µï¼‰å’Œè°ƒèŠ‚æ±‚è§£å™¨å‚æ•°ï¼ˆå¦‚è¿­ä»£æ¬¡æ•°ã€å®¹å¿åº¦ï¼‰æ¥æ”¹å–„æ€§èƒ½

   #æŠ•èµ„ç»„åˆä¼˜åŒ–  
   def optimize_portfolio(cov_matrix, mean_returns, target_return):  
       n = len(mean_returns)  
       P = matrix(cov_matrix.values)  
       q = matrix(np.zeros((n, 1)))  
       G = matrix(np.vstack((-np.array(mean_returns), -np.identity(n))))  
       h = matrix(np.hstack((-target_return, np.zeros(n))))  
       A = matrix(1.0, (1, n))  
       b = matrix(1.0)  

       solvers.options['show_progress'] = False  
       sol = solvers.qp(P, q, G, h, A, b)  

       return sol['x']  

   # ç›®æ ‡è¿”å›  
   target_return = 0.1  # 10% çš„ç›®æ ‡å¹´åŒ–æ”¶ç›Šç‡  
   mean_returns = returns.mean() * 252  

   optimal_weights = optimize_portfolio(cov_matrix, mean_returns, target_return)  
   print("\nOptimal Portfolio Weights:")  
   print([round(w, 4) for w in optimal_weights])  


````
---

### ğŸ”¥Task2

>åŸºäºBlack-Littermançš„æœ€ä½³æŒä»“é…æ¯”æ±‚è§£

#### Background
> â‘ he Markowitz model typically accepts inputs derived either from historical data or from scenario analysis. Scenario analysis suffers from excessive subjectivity and arbitrariness; therefore, the historical-data approachâ€”feeding the model with asset return means and covariancesâ€”is more common in practice. However, this approach has notable drawbacks: the future distribution of asset returns need not match the historical distribution, and historical extrapolation is vulnerable to structural instability (e.g., time-varying means, volatilities, and correlations). Moreover, Markowitz allocations are highly sensitive to input parameters; even small errors in estimated means or covariances can induce large swings in portfolio weights, undermining implementability and robustness. <br>â‘¡The Blackâ€“Litterman model was developed precisely to address these issues. Its central idea is to combine the investorâ€™s subjective views on broad asset classes with the marketâ€™s equilibrium returns (the prior expected returns) via a Bayesian updating scheme, thereby producing calibrated posterior expected returns. In this formulation, the prior distribution of expected returns can be modeled as a multivariate normal prior in the Bayesian sense; the investorâ€™s subjective views act as the likelihood function (i.e., new information reflecting judgments formed from external signals about asset return dynamics); and the posterior expected returns are obtained from the posterior distribution.<br>â‘¢In essence, the model fuses investor views with equilibrium returns to generate a new vector of expected returns. The prior is modeled as a multivariate normal distribution, the investor views constitute the likelihood, and the posterior expected returns are derived from the posterior distribution.
<br>â‘ Markowitzæ¨¡å‹è¾“å…¥å‚æ•°åŒ…æ‹¬å†å²æ•°æ®æ³•å’Œæƒ…æ™¯åˆ†ææ³•ä¸¤ç§æ–¹æ³•,æƒ…æ™¯åˆ†ææ³•çš„ç¼ºç‚¹æ˜¯ä¸»è§‚å› ç´ ,éšæ„æ€§å¤ªå¼º,å› æ­¤ä½¿ç”¨å†å²æ•°æ®æ³•, å°†èµ„äº§çš„å‡å€¼å’Œåæ–¹å·®è¾“å…¥æ¨¡å‹æ˜¯æ¯”è¾ƒå¸¸è§çš„ä½œæ³•. æ­¤åšæ³•å­˜åœ¨æ˜¾è‘—ä¸è¶³:æœªæ¥çš„èµ„äº§æ”¶ç›Šç‡åˆ†å¸ƒæœªå¿…ä¸å†å²åˆ†å¸ƒä¸€è‡´ï¼ŒåŒæ—¶å†å²å¤–æ¨å­˜åœ¨ç»“æ„æ€§ä¸ç¨³å®šé£é™©ï¼ˆå¦‚å‡å€¼ã€æ³¢åŠ¨ç‡ã€ç›¸å…³æ€§éšæ—¶é—´æ¼‚ç§»ï¼‰ã€‚ æ­¤å¤–, Markowitz æ¨¡å‹ç»“æœå¯¹è¾“å…¥å‚æ•°é«˜åº¦æ•æ„Ÿï¼Œå¾®å°çš„å‡å€¼æˆ–åæ–¹å·®è¯¯å·®å¯èƒ½å¯¼è‡´é…ç½®æƒé‡å‘ç”Ÿå·¨å¹…å˜åŒ–ï¼Œè¿›è€Œå½±å“å¯å®æ–½æ€§ä¸ç¨³å¥æ€§ã€‚<br>â‘¡Black-Littermanæ¨¡å‹å°±æ˜¯åŸºäºæ­¤çš„æ”¹è¿›. å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æŠ•èµ„è€…å¯¹å¤§ç±»èµ„äº§çš„ä¸»è§‚è§‚ç‚¹ä¸å¸‚åœºå‡è¡¡æ”¶ç›Šç‡ï¼ˆå…ˆéªŒé¢„æœŸæ”¶ç›Šï¼‰è¿›è¡Œè´å¶æ–¯å¼èåˆï¼Œå½¢æˆç»è¿‡æ ¡å‡†çš„æ–°çš„é¢„æœŸæ”¶ç›Šï¼ˆåéªŒé¢„æœŸæ”¶ç›Š. è¿™é‡Œçš„å…ˆéªŒé¢„æœŸæ”¶ç›Šç‡çš„åˆ†å¸ƒå¯ä»¥æ˜¯è´å¶æ–¯æ¨æ–­ä¸­çš„å…ˆéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒå½¢å¼,æŠ•èµ„è€…çš„ä¸»è§‚è§‚ç‚¹å°±æ˜¯è´å¶æ–¯æ¨æ–­ä¸­çš„ä¼¼ç„¶å‡½æ•°(å¯ä»¥çœ‹ä½œæ–°çš„ä¿¡æ¯, å› ä¸ºåšå‡ºä¸»è§‚åˆ¤æ–­å¿…ç„¶æ˜¯ä»å¤–ç•Œè·å–å¾—åˆ°äº†è¿™äº›èµ„äº§çš„æ”¶ç›Šç‡å˜åŒ–ä¿¡æ¯), è€Œç›¸åº”çš„, åéªŒé¢„æœŸæ”¶ç›Šç‡ä¹Ÿå¯ä»¥ä»åéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°ä¸­å¾—åˆ°<br>â‘¢æ ¸å¿ƒæ€æƒ³æ˜¯å°†æŠ•èµ„è€…å¯¹å¤§ç±»èµ„äº§çš„è§‚ç‚¹ä¸å¸‚åœºå‡è¡¡æ”¶ç›Šç‡ç›¸ç»“åˆ,ä»è€Œå½¢æˆæ–°çš„é¢„æœŸæ”¶ç›Šç‡ï¼Œæ˜¯è´å¶æ–¯æ¨æ–­ä¸­çš„å…ˆéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒå½¢å¼,æŠ•èµ„è€…çš„ä¸»è§‚è§‚ç‚¹æ˜¯ä¼¼ç„¶å‡½æ•°, åéªŒé¢„æœŸæ”¶ç›Šç‡ä»åéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°ä¸­å¾—åˆ°ã€‚

#### æ±‚è§£æ­¥éª¤
>â‘ Prior construction:The covariance matrix used in the prior density is typically based on the covariance matrix of historical returns.<br>Determine the vector of market-expected returns, i.e., the prior mean of expected returns. Alternatively, one may infer the market-implied equilibrium return vector from existing expected returns and variances (reverse optimization). When using this approach, the risk-free rate must be specified.<br>â‘¡Incorporation of investor views:Integrate investor views by specifying the viewsâ€™ mean vector (reflecting the investorâ€™s directional/relative expectations), and the viewsâ€™ uncertainty via a views covariance (often linked to the variance of the view variables and the investorâ€™s confidence). <br>â‘¢Notation and calibration parameters:Ï„:a scalar that scales the covariance of the equilibrium returns, often interpreted as an adjustment reflecting confidence in the prior (smaller Ï„ indicates higher confidence in the prior).
Î£: the covariance matrix of historical asset returns.P: the pick matrix mapping assets to views (the â€œviews matrixâ€).Î©: the covariance matrix associated with the likelihood (the uncertainty of investor views). A common specification is a diagonal matrix with entries derived from the diagonal of the P^T(Ï„Î£)P. Î :the prior (equilibrium) expected returns. <br>â‘£Portfolio optimization:Feed the posterior (adjusted) expected returns and the chosen covariance matrix back into the Markowitz meanâ€“variance optimizer to obtain the final portfolio weights.
<br>â‘ é€šå¸¸ä½¿ç”¨å†å²æ•°æ®ä¼°è®¡é¢„æœŸæ”¶ç›Šç‡çš„åæ–¹å·®çŸ©é˜µä½œä¸ºå…ˆéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°çš„åæ–¹å·®çš„åŸºç¡€.<br>ç¡®å®šå¸‚åœºé¢„æœŸä¹‹æ”¶ç›Šç‡å‘é‡, ä¹Ÿå°±æ˜¯å…ˆéªŒé¢„æœŸæ”¶ç›Šä¹‹æœŸæœ›å€¼. ä½œä¸ºå…ˆéªŒæ¦‚ç‡å¯†åº¦å‡½æ•°çš„å‡å€¼. æˆ–è€…ä½¿ç”¨ç°æœ‰çš„æœŸæœ›å€¼å’Œæ–¹å·®æ¥åæ¨å¸‚åœºéšå«çš„å‡è¡¡æ”¶ç›Šç‡(Implied Equilibrium Return Vector), ä¸è¿‡åœ¨ä½¿ç”¨è¿™ç§æ–¹æ³•æ—¶, éœ€è¦çŸ¥é“æ— é£é™©æ”¶ç›Šç‡Rfçš„å¤§å°.<br>â‘¡èåˆæŠ•èµ„äººçš„ä¸ªäººè§‚ç‚¹,å³æ ¹æ®å†å²æ•°æ®(çœ‹æ³•å˜é‡çš„æ–¹å·®)å’Œä¸ªäººçœ‹æ³•(çœ‹æ³•å‘é‡çš„å‡å€¼) <br>â‘¢Ï„æ˜¯å‡è¡¡æ”¶ç›Šç‡åæ–¹å·®çš„è°ƒæ•´ç³»æ•°,å¯ä»¥æ ¹æ®ä¿¡å¿ƒæ°´å¹³æ¥åˆ¤æ–­.Ï„æ˜¯å‡è¡¡æ”¶ç›Šç‡åæ–¹å·®çš„è°ƒæ•´ç³»æ•°ï¼Œ Sigmaæ˜¯å†å²èµ„äº§æ”¶ç›Šç‡çš„åæ–¹å·®çŸ©é˜µ, Pæ˜¯æŠ•èµ„è€…çš„è§‚ç‚¹çŸ©é˜µ,Î© æ˜¯ä¼¼ç„¶å‡½æ•°(å³æŠ•èµ„è€…è§‚ç‚¹å‡½æ•°)ä¸­çš„åæ–¹å·®çŸ©é˜µ,å…¶å€¼ä¸ºP^T(Ï„Î£)Pçš„å¯¹è§’é˜µ, Î æ˜¯å…ˆéªŒæ”¶ç›Šç‡çš„æœŸæœ›å€¼ <br>â‘£æŠ•èµ„ç»„åˆä¼˜åŒ–ï¼šå°†ä¿®æ­£åçš„æœŸæœ›å€¼ä¸åæ–¹å·®é‡æ–°ä»£å…¥é©¬ç§‘ç»´èŒ¨æŠ•èµ„ç»„åˆæ¨¡å‹æ±‚è§£




### ğŸ´ å…·ä½“ä»»åŠ¡å®ç°çš„ç®—æ³•

````python
```
# Black-Litterman æ¨¡å‹å®šä¹‰  
# tau æ˜¯ä¸€ä¸ªæ ‡é‡å‚æ•°ï¼Œ
#é€šå¸¸å–å€¼åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚å®ƒè¡¨ç¤ºæˆ‘ä»¬å¯¹å¸‚åœºå‡è¡¡çš„ä¿¡å¿ƒç›¸å¯¹äºæ ·æœ¬ä¿¡æ¯çš„ç¨‹åº¦ã€‚
# taué€šå¸¸é€‰ 1/é€‰è§‚å¯Ÿçš„äº¤æ˜“æ—¥é•¿åº¦
def blacklitterman(returns, tau, P, Q):  
    mu = returns.mean()  
    sigma = returns.cov()  
    pil = np.expand_dims(mu, axis=0).T  # å¸‚åœºå‡è¡¡é¢„æœŸæ”¶ç›Šç‡ï¼ˆÎ ï¼‰  
    ts = tau * sigma  
    ts_inv = linalg.inv(ts)  
    Omega = np.dot(np.dot(P, ts), P.T) * np.eye(Q.shape[0])  # è§‚ç‚¹è¯„ä»·çŸ©é˜µ  
    Omega_inv = linalg.inv(Omega)  
    # è®¡ç®—åéªŒé¢„æœŸæ”¶ç›Šç‡  
    er = linalg.inv(ts_inv + np.dot(np.dot(P.T, Omega_inv), P)) @ (np.dot(ts_inv, pil) + np.dot(np.dot(P.T, Omega_inv), Q))  
    # è®¡ç®—åéªŒåæ–¹å·®çŸ©é˜µ  
    posteriorSigma = linalg.inv(ts_inv + np.dot(np.dot(P.T, Omega_inv), P))  
    return [er, posteriorSigma]  
```

````python
```

# å®šä¹‰æŠ•èµ„è€…çš„è§‚ç‚¹  
pick1 = np.array([1, 0, 1, 1, 1])  # è§‚ç‚¹1æ¶‰åŠGOOG, AAPL, NVDA, AMZN  
q1 = np.array([0.003 * 4])        # å¯¹åº”çš„è§‚ç‚¹é¢„æœŸæ”¶ç›Šç‡  

pick2 = np.array([0.5, 0.5, 0, 0, -1])  # è§‚ç‚¹2æ˜¯GOOGå’ŒMSFTçš„ç»„åˆæ¯”AMZNè¡¨ç°æ›´å¥½  
q2 = np.array([0.001])                  # å¯¹åº”çš„è§‚ç‚¹é¢„æœŸæ”¶ç›Šç‡  

P = np.array([pick1, pick2])  
Q = np.array([q1, q2])

# è®¡ç®— Black-Litterman åéªŒé¢„æœŸæ”¶ç›Šç‡å’Œåæ–¹å·®çŸ©é˜µ  
res = blacklitterman(log_return, 1/252, P, Q)  

# res[0]: åéªŒå‡å€¼   # res[1]ï¼šåéªŒåæ–¹å·®çŸ©é˜µ  

````

````python
```

#æœ€å°æ–¹å·®ç»„åˆçš„èµ„äº§é…ç½®æƒé‡ (blminVar)
# å®šä¹‰æœ€å°æ–¹å·®ç»„åˆè®¡ç®—å‡½æ•°  
def blminVar(cov_matrix):  
    n = cov_matrix.shape[0]  
    ones = np.ones(n)  
    inv_cov = linalg.inv(cov_matrix)  
    weights = inv_cov @ ones / (ones.T @ inv_cov @ ones)  
    return weights  

# è®¡ç®—æœ€å°æ–¹å·®ç»„åˆçš„æƒé‡  
weights = blminVar(res[1])  

# å°†ç»“æœè½¬æ¢ä¸º pandas Seriesï¼Œæ–¹ä¾¿å±•ç¤º  
weights_series = pd.Series(weights, index=tickers) 

````


````python
```

# å¯è§†åŒ–æƒé‡åˆ†å¸ƒ  
plt.figure(figsize=(10,6))  
weights_series.plot(kind='bar')  
plt.title('Minimum Variance Portfolio Weights (Black-Litterman)')  
plt.ylabel('Weight')  
plt.xlabel('Assets')  
plt.grid(True)  
plt.savefig('Minimum Variance Portfolio Weights (Black-Litterman).png', dpi=500)
plt.show()

````

````python
```

#2. æ¯”è¾ƒ Black-Litterman ç»„åˆä¸éšæœºç»„åˆçš„é¢„æœŸæ”¶ç›Šå’Œé£é™©  

weights_BL=weights_series
# è®¡ç®— Black-Litterman ç»„åˆçš„é¢„æœŸæ”¶ç›Šå’Œé£é™©  
mu_BL = res[0].flatten()  
portfolio_return_BL = np.dot(weights_BL, mu_BL)  
portfolio_variance_BL = np.dot(weights_BL, np.dot(res[1], weights_BL))  
portfolio_std_BL = np.sqrt(portfolio_variance_BL)  

# ç”Ÿæˆéšæœºç»„åˆ  
num_portfolios = 5000  
np.random.seed(42)  # ä¸ºäº†ç»“æœå¯é‡å¤  

random_weights = np.random.dirichlet(np.ones(len(tickers)), size=num_portfolios)  
random_returns = random_weights @ mu_BL  
random_variances = np.einsum('ij,ik,jk->i', random_weights, random_weights, res[1])  
random_std = np.sqrt(random_variances)  

# è®¡ç®—éšæœºç»„åˆçš„é¢„æœŸæ”¶ç›Šå’Œé£é™©  
random_returns = random_weights @ mu_BL  
random_std = np.sqrt(random_variances)  

# è®¡ç®—éšæœºç»„åˆçš„å¤æ™®æ¯”ç‡ï¼ˆå‡è®¾æ— é£é™©åˆ©ç‡ä¸º0ï¼‰  
sharpe_random = random_returns / random_std  
sharpe_BL = portfolio_return_BL / portfolio_std_BL  

# 3. å¯è§†åŒ–æ¯”è¾ƒ  

plt.figure(figsize=(12,8))  
plt.scatter(random_std, random_returns, c=sharpe_random, cmap='viridis', alpha=0.5)  
plt.colorbar(label='Sharpe Ratio')  
# ç»˜åˆ¶ Black-Litterman ç»„åˆ  
plt.scatter(portfolio_std_BL, portfolio_return_BL, color='red', marker='*', s=200, label='Black-Litterman Portfolio')  
plt.title('Black-Litterman Portfolio vs Random Portfolios')  
plt.xlabel('Risk (Standard Deviation)')  
plt.ylabel('Expected Return')  
plt.legend()  
plt.grid(True)  
plt.savefig('BL_Portfolio.png', dpi=500)
plt.show()  


````

````python
```

# åˆå§‹åŒ–ä¸€ä¸ªDataFrameæ¥å­˜å‚¨æ‰€æœ‰éšæœºç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡  
num_simulations =5000  
np.random.seed(42)  # ä¸ºäº†å¯é‡å¤æ€§  

# è®¡ç®—ç®€å•æ”¶ç›Šç‡å¹¶å»é™¤ç¼ºå¤±å€¼  
simple_return = data.pct_change()  # è®¡ç®—ç®€å•æ”¶ç›Šç‡  
simple_return = simple_return.dropna(how='all')  # å»é™¤ç¼ºå¤±å€¼


# åˆå§‹åŒ–ä¸€ä¸ªDataFrameæ¥å­˜å‚¨æ‰€æœ‰éšæœºç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡  
cumulative_random_all = pd.DataFrame(index=simple_return.index)  
final_random_returns = []  
def calculate_cumulative_returns(simple_return, weights):  
    """  
    è®¡ç®—ç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡ã€‚  

    å‚æ•°:  
    - simple_return: DataFrameï¼Œæ¯ä¸ªèµ„äº§çš„ç®€å•æ”¶ç›Šç‡ã€‚  
    - weights: æ•°ç»„æˆ–åˆ—è¡¨ï¼Œèµ„äº§çš„æƒé‡ã€‚  

    è¿”å›:  
    - cumulative_returns: Seriesï¼Œç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡ã€‚  
    """  
    # è®¡ç®—ç»„åˆçš„åŠ æƒæ”¶ç›Šç‡  
    portfolio_return = (simple_return @ weights)  
    
    # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡  
    cumulative_returns = (1 + portfolio_return).cumprod() - 1  
    
    return cumulative_returns

# è®¡ç®— Black-Litterman ç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡  
cumulative_bl = calculate_cumulative_returns(simple_return, weights_BL)
````

````python
```
# æ¨¡æ‹Ÿ5000ä¸ªéšæœºç»„åˆ  
for i in range(num_simulations):  
    # ç”Ÿæˆéšæœºæƒé‡  
    random_weights = np.random.random(len(tickers))  
    random_weights /= random_weights.sum()  # æ ‡å‡†åŒ–æƒé‡  
    # è®¡ç®—ç´¯è®¡æ”¶ç›Šç‡  
    cumulative_random = calculate_cumulative_returns(simple_return, random_weights)  
    # å°†æ¯ä¸ªéšæœºç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡å­˜å‚¨åˆ°DataFrame  
    cumulative_random_all[f'Random_{i+1}'] = cumulative_random  
    # è®°å½•æœ€ç»ˆçš„ç´¯è®¡æ”¶ç›Šç‡  
    final_random_returns.append(cumulative_random.iloc[-1])  

# 3. å¯è§†åŒ–æ¯”è¾ƒ  
plt.figure(figsize=(12, 8))  

# ç»˜åˆ¶æ‰€æœ‰éšæœºç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡è·¯å¾„ï¼Œé¢œè‰²ç¨å¾®é€æ˜ä»¥æ˜¾ç¤ºè¶‹åŠ¿  
plt.plot(cumulative_random_all, color='lightgrey', alpha=1, linewidth=1)  

# ç»˜åˆ¶Black-Littermanç»„åˆçš„ç´¯è®¡æ”¶ç›Šç‡è·¯å¾„  
plt.plot(cumulative_bl, color='red', linewidth=2, label='Black-Litterman Portfolio')  

plt.title('Cumulative Returns Comparison')  
plt.xlabel('Date')  
plt.ylabel('Cumulative Return')  
plt.legend()  
plt.grid(True, linestyle='--', alpha=0.7)  
plt.tight_layout()  

plt.savefig('Cumulative Return Comparision.png', dpi=500) 
plt.show()  
````

---



>æŒç»­è®°å½•ä¸­



